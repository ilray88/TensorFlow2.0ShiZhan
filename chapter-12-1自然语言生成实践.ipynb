{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第 12 章 自然语言生成实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 12.1 LSTM 写诗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 12.1.3 实现 LSTM 写诗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['秦川雄帝宅，函谷壮皇居。绮殿千寻起，离宫百雉余。连甍遥接汉，飞观迥凌虚。云日隐层阙，风烟出绮疏。', '岩廊罢机务，崇文聊驻辇。玉匣启龙图，金绳披凤篆。韦编断仍续，缥帙舒还卷。对此乃淹留，欹案观坟典。', '移步出词林，停舆欣武宴。雕弓写明月，骏马疑流电。惊雁落虚弦，啼猿悲急箭。阅赏诚多美，于兹乃忘倦。']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import operator\n",
    "import collections\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 只保留五言绝句\n",
    "def should_keep(paragraphs: List[str]):\n",
    "    return all([len(par) == 12 for par in paragraphs])\n",
    "\n",
    "# 读取数据\n",
    "def read_all_data(path: str):\n",
    "    poems = []\n",
    "    files = glob.glob(os.path.join(path, 'poet.tang.*.json'))\n",
    "    for file in files:\n",
    "        file_data = json.load(open(file, 'r',encoding='utf-8'))\n",
    "        for item in file_data:\n",
    "            if should_keep(item['paragraphs']):\n",
    "                poem = ''.join(item['paragraphs'])\n",
    "                poems.append(poem)\n",
    "    return poems\n",
    "\n",
    "poems = read_all_data('data/poetry')\n",
    "# 为了加快训练，这里只取了 10000 条诗，可以根据自己资源增加或者减少\n",
    "poems = poems[:10000]\n",
    "print(poems[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Processor(object):\n",
    "\n",
    "    def build_token_dict(self, corpus: List[List[str]]):\n",
    "        \"\"\"\n",
    "        构建 token 字典，这个方法将会遍历分词后的语料，构建一个标记频率字典和标记与索引的映射字典\n",
    "\n",
    "        Args:\n",
    "            corpus: 所有分词后的语料\n",
    "        \"\"\"\n",
    "        token2idx = {\n",
    "            '<PAD>': 0,\n",
    "            '<UNK>': 1,\n",
    "            '<BOS>': 2,\n",
    "            '<EOS>': 3\n",
    "        }\n",
    "\n",
    "        token2count = {}\n",
    "        for sentence in corpus:\n",
    "            for token in sentence:\n",
    "                count = token2count.get(token, 0)\n",
    "                token2count[token] = count + 1\n",
    "        # 按照词频降序排序\n",
    "        sorted_token2count = sorted(token2count.items(),\n",
    "                                    key=operator.itemgetter(1),\n",
    "                                    reverse=True)\n",
    "        token2count = collections.OrderedDict(sorted_token2count)\n",
    "\n",
    "        for token in token2count.keys():\n",
    "            if token not in token2idx:\n",
    "                token2idx[token] = len(token2idx)\n",
    "        return token2idx, token2count\n",
    "\n",
    "    @staticmethod\n",
    "    def numerize_sequences(sequence: List[str],\n",
    "                           token2index: Dict[str, int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        将分词后的标记（token）数组转换成对应的索引数组\n",
    "        如 ['我', '想', '睡觉'] -> [10, 313, 233]\n",
    "\n",
    "        Args:\n",
    "            sequence: 分词后的标记数组\n",
    "            token2index: 索引词典\n",
    "        Returns: 输入数据对应的索引数组\n",
    "        \"\"\"\n",
    "        token_result = []\n",
    "        for token in sequence:\n",
    "            token_index = token2index.get(token)\n",
    "            if token_index is None:\n",
    "                token_index = token2index['<UNK>']\n",
    "            token_result.append(token_index)\n",
    "        return token_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = Processor()\n",
    "# 这里我们对所有的诗做了基于字的分词，然后再构建词表\n",
    "p.token2idx, p.token2count = p.build_token_dict([list(seq) for seq in poems])\n",
    "# 由于我们这是文本生成，还需要一个索引到词的映射关系\n",
    "p.idx2token = dict([(v, k) for k,v in p.token2idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 先定义一下两个全局变量，输入序列长度和批次大小\n",
    "INPUT_LEN = 6\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "# 所有的诗整合为一个大字符串，方便后续遍历\n",
    "corpus = ''.join(poems)\n",
    "\n",
    "def data_generator():\n",
    "    t = 0\n",
    "    while True:\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        for i in range(BATCH_SIZE):\n",
    "            # 取出 t 到 t + INPUT_LEN 位置的字符串序列作为输入\n",
    "            x = corpus[t: t + INPUT_LEN]\n",
    "            # 取出 t + INPUT_LEN 位置的字符串作为输出\n",
    "            y = corpus[t + INPUT_LEN]\n",
    "\n",
    "            # 输入输出转换为数字\n",
    "            x_data.append(p.numerize_sequences(list(x), p.token2idx))\n",
    "            y_data.append(p.token2idx[y])\n",
    "\n",
    "            t += 1\n",
    "            # 当游标到了最后，从头开始遍历\n",
    "            if t + 1 >= len(corpus) - INPUT_LEN:\n",
    "                t = 0\n",
    "\n",
    "        x_data = np.array(x_data)\n",
    "        # 将输出序列转换为 one-hot 编码\n",
    "        y_data = to_categorical(y_data, len(p.token2idx))\n",
    "\n",
    "        yield x_data, y_data\n",
    "        \n",
    "# 初始化数据生成器\n",
    "# 如果想观察生成器每一步产生的数据，初始化生成器后调用 `next(gen)` 函数观察\n",
    "gen = data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_2/strided_slice:0) to a numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_8840/529235431.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0mL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoken2idx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'softmax'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m ])\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    455\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 457\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    458\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    459\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, layers, name)\u001B[0m\n\u001B[0;32m    112\u001B[0m       \u001B[0mtf_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massert_no_legacy_layers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m       \u001B[1;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlayers\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 114\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlayer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    455\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 457\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    458\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    459\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36madd\u001B[1;34m(self, layer)\u001B[0m\n\u001B[0;32m    194\u001B[0m       \u001B[1;31m# If the model is being built continuously on top of an input layer:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m       \u001B[1;31m# refresh its output.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m       \u001B[0moutput_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    197\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    621\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    622\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 623\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mRNN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    624\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    625\u001B[0m     \u001B[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    840\u001B[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001B[0;32m    841\u001B[0m                   \u001B[1;32mwith\u001B[0m \u001B[0mauto_control_deps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAutomaticControlDependencies\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0macd\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 842\u001B[1;33m                     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcast_inputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    843\u001B[0m                     \u001B[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    844\u001B[0m                     \u001B[1;31m# circular dependencies.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, mask, training, initial_state)\u001B[0m\n\u001B[0;32m    891\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mcall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    892\u001B[0m     \u001B[1;31m# LSTM does not support constants. Ignore it during process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 893\u001B[1;33m     \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_process_inputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minitial_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    894\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    895\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m_process_inputs\u001B[1;34m(self, inputs, initial_state, constants)\u001B[0m\n\u001B[0;32m    796\u001B[0m       \u001B[0minitial_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    797\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 798\u001B[1;33m       \u001B[0minitial_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_initial_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    799\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    800\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minitial_state\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36mget_initial_state\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m    604\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mget_initial_state_fn\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    605\u001B[0m       init_state = get_initial_state_fn(\n\u001B[1;32m--> 606\u001B[1;33m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001B[0m\u001B[0;32m    607\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    608\u001B[0m       init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36mget_initial_state\u001B[1;34m(self, inputs, batch_size, dtype)\u001B[0m\n\u001B[0;32m   2312\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mget_initial_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2313\u001B[0m     return list(_generate_zero_filled_state_for_cell(\n\u001B[1;32m-> 2314\u001B[1;33m         self, inputs, batch_size, dtype))\n\u001B[0m\u001B[0;32m   2315\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2316\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m_generate_zero_filled_state_for_cell\u001B[1;34m(cell, inputs, batch_size, dtype)\u001B[0m\n\u001B[0;32m   2750\u001B[0m     \u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2751\u001B[0m     \u001B[0mdtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2752\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0m_generate_zero_filled_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2753\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2754\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m_generate_zero_filled_state\u001B[1;34m(batch_size_tensor, state_size, dtype)\u001B[0m\n\u001B[0;32m   2766\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2767\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_sequence\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2768\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcreate_zeros\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2769\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2770\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcreate_zeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    533\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    534\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 535\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    536\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    537\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    533\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    534\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 535\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    536\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    537\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36mcreate_zeros\u001B[1;34m(unnested_state_size)\u001B[0m\n\u001B[0;32m   2763\u001B[0m     \u001B[0mflat_dims\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtensor_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_shape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munnested_state_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2764\u001B[0m     \u001B[0minit_state_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mbatch_size_tensor\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mflat_dims\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2765\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minit_state_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2766\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2767\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_sequence\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mzeros\u001B[1;34m(shape, dtype, name)\u001B[0m\n\u001B[0;32m   2347\u001B[0m         \u001B[1;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2348\u001B[0m         \u001B[1;31m# to prevent serialized GraphDefs from becoming too large.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2349\u001B[1;33m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_constant_if_small\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzero\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2350\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2351\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36m_constant_if_small\u001B[1;34m(value, shape, dtype, name)\u001B[0m\n\u001B[0;32m   2304\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_constant_if_small\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2305\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2306\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2307\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2308\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mprod\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36mprod\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   3050\u001B[0m     \"\"\"\n\u001B[0;32m   3051\u001B[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001B[1;32m-> 3052\u001B[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001B[0m\u001B[0;32m   3053\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3054\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpasskwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mufunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduce\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpasskwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\0ilraypan\\python_work\\env\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    734\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    735\u001B[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001B[1;32m--> 736\u001B[1;33m                               \" array.\".format(self.name))\n\u001B[0m\u001B[0;32m    737\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    738\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__len__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: Cannot convert a symbolic Tensor (lstm_2/strided_slice:0) to a numpy array."
     ]
    }
   ],
   "source": [
    "L = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    L.Embedding(input_dim=len(p.token2idx), output_dim=50, input_shape=(6, )),\n",
    "    L.LSTM(128),\n",
    "    L.Dropout(0.1),\n",
    "    L.Dense(len(p.token2idx), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# 每个 epoch 步数等于（整个语料序列长度 - 窗口长度）除以批次大小\n",
    "steps = (len(corpus) - INPUT_LEN - 1) // BATCH_SIZE\n",
    "model.fit_generator(gen,\n",
    "                    steps_per_epoch=steps,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds: np.ndarray, temperature: float = 1.0) -> int:\n",
    "    \"\"\"\n",
    "    使用 softmax 温度随机采样\n",
    "    当 temperature = 1.0 时，模型输出正常\n",
    "    当 temperature = 0.5 时，模型输出比较open\n",
    "    当 temperature = 1.5 时，模型输出比较保守\n",
    "\n",
    "    Args:\n",
    "        preds: 模型预测结果\n",
    "        temperature: softmax 温度\n",
    "    Returns:\n",
    "        采样结果\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    exp_preds = np.power(preds, 1. / temperature)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    pro = np.random.choice(range(len(preds)), 1, p=preds)\n",
    "    return int(pro.squeeze())\n",
    "\n",
    "def predict_next_char(input_seq: List[str],\n",
    "                      temperature: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    输入序列，预测下一个字符\n",
    "\n",
    "    Args:\n",
    "        input_seq: 输入序列\n",
    "        temperature: softmax 温度\n",
    "    Returns:\n",
    "        下一个字符串\n",
    "    \"\"\"\n",
    "    if len(input_seq) < INPUT_LEN:\n",
    "        raise ValueError(f'seq length must large than {INPUT_LEN}')\n",
    "\n",
    "    input_seq = input_seq[-INPUT_LEN:]\n",
    "    input_tensor = p.numerize_sequences(input_seq, p.token2idx)\n",
    "    input_tensor = np.array([input_tensor])\n",
    "    preds = model.predict(input_tensor)[0]\n",
    "    pred_idx = sample(preds, temperature)\n",
    "    pred_char = p.idx2token[pred_idx]\n",
    "    return pred_char\n",
    "\n",
    "def pred_with_start(input_seq: List[str],\n",
    "                    temperature: float = 1.0) -> List[str]:\n",
    "    \"\"\"\n",
    "    以给定字符串作为开头写诗\n",
    "\n",
    "    Args:\n",
    "        input_seq: 诗开头字符串\n",
    "        temperature: softmax 温度\n",
    "    Returns:\n",
    "        生成的诗歌序列\n",
    "    \"\"\"\n",
    "    result = input_seq\n",
    "    # 如果长度不足，则随机取一首诗补全\n",
    "    if len(input_seq) < INPUT_LEN:\n",
    "        padding_poem = list(random.choice(poems))\n",
    "    else:\n",
    "        padding_poem = []\n",
    "\n",
    "    # 当序列中出现四个 。 或者序列长度超过 100 时候停止\n",
    "    # 100 这个限制主要是为了避免出现死循环\n",
    "    should_continue = True\n",
    "    while should_continue:\n",
    "        pred_char = predict_next_char(padding_poem + result, temperature)\n",
    "        result.append(pred_char)\n",
    "        if result.count('。') == 4 or len(result) > 100:\n",
    "            should_continue = False\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for temp in [0.3, 0.6, 1.0, 1.2, 1.5]:\n",
    "    print(f'\\nTemperature: {temp}')\n",
    "    for _ in range(3):\n",
    "        print(''.join(pred_with_start(['冬', '日'], temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_hide(head_tokens: List[str],\n",
    "                 temperature: float = 1.0) -> List[str]:\n",
    "    \"\"\"\n",
    "    写藏头诗\n",
    "\n",
    "    Args:\n",
    "        head_tokens: 每一句的第一个字组成的数组\n",
    "        temperature: softmax 温度\n",
    "    Returns:\n",
    "        生成的诗歌序列\n",
    "    \"\"\"\n",
    "    padding_poem = list(random.choice(poems))\n",
    "    result = []\n",
    "\n",
    "    for i in range(4):\n",
    "        result.append(head_tokens[i])\n",
    "        sentence_end = False\n",
    "        while not sentence_end:\n",
    "            char = predict_next_char(padding_poem + result, temperature)\n",
    "            result.append(char)\n",
    "            if char == '。' or len(result) > 100:\n",
    "                sentence_end = True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for temp in [0.3, 0.6, 1.0, 1.2, 1.5]:\n",
    "    print(f'\\nTemperature: {temp}')\n",
    "    for _ in range(3):\n",
    "        print(''.join(predict_hide(['机', '器', '学', '习'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}